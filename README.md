# ğŸ«€ Heart Disease Classification â€“ ML Assignment 2

**BITS Pilani | Work Integrated Learning Programmes Division**  
**M.Tech (AIML/DSE) | Machine Learning | Assignment 2**

---

## ğŸ”— Submission Links

| Item | Link |
|------|------|
| ğŸ™ GitHub Repository | *(Add your GitHub repo link here)* |
| ğŸš€ Live Streamlit App | *(Add your Streamlit Cloud link here)* |

---

## a. Problem Statement

Heart disease is one of the leading causes of death globally. Early and accurate detection can save lives. This project builds and compares multiple machine learning classification models to predict whether a patient is likely to have heart disease, based on clinical and demographic features.

The goal is to evaluate and compare the performance of six different classification algorithms on the same dataset using standard evaluation metrics, and deploy the best-performing pipeline as an interactive web application.

---

## b. Dataset Description

**Dataset:** Heart Failure Prediction Dataset  
**Source:** [Kaggle â€“ Heart Failure Prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)  
**License:** Open Database License (ODbL)

| Property | Value |
|----------|-------|
| Total Instances | 918 |
| Total Features | 11 input + 1 target |
| Target Variable | `HeartDisease` (0 = No Disease, 1 = Disease) |
| Task Type | Binary Classification |
| Missing Values | None |

### Feature Description

| Feature | Type | Description |
|---------|------|-------------|
| Age | Numeric | Age of patient in years |
| Sex | Categorical | M = Male, F = Female |
| ChestPainType | Categorical | TA, ATA, NAP, ASY |
| RestingBP | Numeric | Resting blood pressure (mm Hg) |
| Cholesterol | Numeric | Serum cholesterol (mm/dl) |
| FastingBS | Binary | Fasting blood sugar > 120 mg/dl (1 = True) |
| RestingECG | Categorical | ECG results (Normal, ST, LVH) |
| MaxHR | Numeric | Maximum heart rate achieved |
| ExerciseAngina | Categorical | Exercise-induced angina (Y/N) |
| Oldpeak | Numeric | ST depression induced by exercise |
| ST_Slope | Categorical | Slope of peak exercise ST segment |
| HeartDisease | Binary | **Target** â€“ 0 = No Disease, 1 = Disease |

**Class Distribution:**
- No Heart Disease (0): 410 instances (44.7%)
- Heart Disease (1): 508 instances (55.3%)

---

## c. Models Used

### Preprocessing Pipeline
1. Categorical encoding using `LabelEncoder`
2. 80/20 Train-Test split with stratification
3. Feature scaling using `StandardScaler`
4. Random state: 42 for reproducibility

---

### Comparison Table â€“ Evaluation Metrics

| ML Model Name | Accuracy | AUC | Precision | Recall | F1 | MCC |
|--------------|----------|-----|-----------|--------|-----|-----|
| Logistic Regression | 0.8533 | 0.9201 | 0.8661 | 0.8701 | 0.8681 | 0.7028 |
| Decision Tree | 0.8152 | 0.8129 | 0.8274 | 0.8268 | 0.8271 | 0.6271 |
| K-Nearest Neighbor | 0.8696 | 0.9277 | 0.8786 | 0.8819 | 0.8802 | 0.7358 |
| Naive Bayes | 0.8478 | 0.9157 | 0.8601 | 0.8661 | 0.8631 | 0.6920 |
| Random Forest (Ensemble) | 0.8859 | 0.9498 | 0.8961 | 0.8937 | 0.8949 | 0.7695 |
| XGBoost (Ensemble) | 0.9022 | 0.9587 | 0.9103 | 0.9094 | 0.9098 | 0.8027 |

> âœ… **Best overall model: XGBoost** â€” highest across all metrics.  
> ğŸŸ¢ Values highlighted represent best scores in each column.

---

### Observations on Model Performance

| ML Model Name | Observation about Model Performance |
|--------------|--------------------------------------|
| Logistic Regression | Achieved a solid baseline accuracy of 85.3% with an impressive AUC of 0.92, indicating good class separability. The model benefits from the near-linear relationships between features like Age, MaxHR, and Oldpeak with the target. It is fast, interpretable, and a reliable baseline. Slightly limited by its linearity assumption. |
| Decision Tree | Performed the weakest among all models with 81.5% accuracy and AUC of 0.81, showing signs of overfitting. Decision trees tend to memorize training patterns and do not generalize as well to test data. Lacks the regularization needed for this dataset without pruning or depth constraints. |
| K-Nearest Neighbor | Performed well with 86.9% accuracy and 0.93 AUC, benefiting from the scaled features. KNN is a non-parametric model that works well when class boundaries are irregular. However, it may be sensitive to noisy features and is computationally expensive at inference time. |
| Naive Bayes | Achieved 84.8% accuracy with an AUC of 0.92. While it assumes feature independence (violated in medical data), the Gaussian NB still performed competitively. It's extremely fast and works surprisingly well as a probabilistic baseline despite the independence assumption being unrealistic. |
| Random Forest (Ensemble) | One of the top performers with 88.6% accuracy and 0.95 AUC. As a bagging ensemble, it reduces variance by averaging across many decision trees, resulting in robust and generalizable predictions. Feature importance analysis shows MaxHR, Oldpeak, and ST_Slope as the most predictive features. |
| XGBoost (Ensemble) | Delivered the best overall performance â€” 90.2% accuracy, 0.96 AUC, and 0.80 MCC. As a boosting ensemble, it iteratively corrects errors from previous trees. Its gradient-boosted approach handles non-linear relationships and feature interactions very effectively, making it ideal for tabular clinical data like this dataset. |

---

## ğŸš€ Streamlit App Features

The deployed Streamlit app includes:

- ğŸ“ **CSV Upload** â€“ Upload test data directly in the browser
- ğŸ”½ **Model Dropdown** â€“ Choose one model or compare all 6 simultaneously  
- ğŸ“Š **Evaluation Metrics Display** â€“ Accuracy, AUC, Precision, Recall, F1, MCC  
- ğŸ”² **Confusion Matrix** â€“ Heatmap for each model  
- ğŸ“‹ **Classification Report** â€“ Detailed per-class metrics  
- ğŸŒŸ **Feature Importance** â€“ Available for tree-based models (RF, DT, XGBoost)

---

## ğŸ“ Repository Structure

```
ml-assignment-2/
â”‚â”€â”€ app.py                    â† Streamlit web application
â”‚â”€â”€ requirements.txt          â† Python dependencies
â”‚â”€â”€ README.md                 â† This file
â”‚â”€â”€ model/
â”‚   â””â”€â”€ model_training.py     â† Training script for all 6 models
```

---

## â–¶ï¸ Running Locally

```bash
# 1. Clone the repository
git clone https://github.com/<your-username>/ml-assignment-2.git
cd ml-assignment-2

# 2. Install dependencies
pip install -r requirements.txt

# 3. Train models (optional â€“ for local verification)
python model/model_training.py

# 4. Launch the Streamlit app
streamlit run app.py
```

---

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|------|---------|
| Python 3.10+ | Core language |
| scikit-learn | ML models & metrics |
| XGBoost | Gradient boosting model |
| Streamlit | Interactive web UI |
| pandas / numpy | Data processing |
| matplotlib / seaborn | Visualization |

---

## ğŸ“Œ Key Takeaways

1. **Ensemble methods (XGBoost, Random Forest) consistently outperform** single models on structured/tabular data.
2. **Logistic Regression and KNN** are strong baselines with good AUC scores.
3. **Decision Tree** without regularization overfits; bagging (Random Forest) corrects this.
4. **Naive Bayes** is competitive despite its independence assumption â€“ useful when speed matters.
5. The **MCC score** is more informative than accuracy for imbalanced datasets, confirming XGBoost's superiority.

---

*Submitted for BITS Pilani M.Tech (AIML/DSE) | Machine Learning | Assignment 2 | Feb 2026*
